{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from sms_spam_collection/SMSSpamCollection\n",
      "Loaded 5572 records\n",
      "Saving raw data to raw_data.csv\n",
      "Raw data saved raw_data.csv\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add raw_data.csv.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data(file_path):\n",
    "    \"\"\"Load raw SMS data from file\"\"\"\n",
    "    print(f\"Loading raw data from {file_path}\")\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
    "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    return df\n",
    "\n",
    "def save_raw_data(df, path='raw_data.csv'):\n",
    "    \"\"\"Save raw data to CSV file and track with DVC\"\"\"\n",
    "    print(f\"Saving raw data to {path}\")\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Raw data saved {path}\")\n",
    "\n",
    "# Load and save raw data\n",
    "filepath = 'sms_spam_collection/SMSSpamCollection'\n",
    "sms_data = load_raw_data(filepath)\n",
    "save_raw_data(sms_data)\n",
    "\n",
    "# Track the raw data file with DVC\n",
    "datapath = 'raw_data.csv'\n",
    "!dvc init --subdir\n",
    "!dvc add {datapath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "message",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3820ecfb-ba6e-4e43-90bb-83db70cb73be",
       "rows": [
        [
         "0",
         "0",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "0",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "1",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "0",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "0",
         "Nah I don't think he goes to usf, he lives around here though"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data with random_state=0\n",
      "Train data shape: (3900, 2)\n",
      "Validation data shape: (836, 2)\n",
      "Test data shape: (836, 2)\n"
     ]
    }
   ],
   "source": [
    "def process_and_split_data(df, random_state=0):\n",
    "    \"\"\"Process and split data into train/validation/test sets\"\"\"\n",
    "    print(f\"Splitting data with random_state={random_state}\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('datasets_processed', exist_ok=True)\n",
    "    \n",
    "    # Split the data into train (70%), validation (15%), and test (15%) sets\n",
    "    train_data, temp_data = train_test_split(\n",
    "        df, \n",
    "        train_size=0.7, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, \n",
    "        test_size=0.5, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Define paths for split files\n",
    "    train_path = 'datasets_processed/train.csv'\n",
    "    val_path = 'datasets_processed/validation.csv'\n",
    "    test_path = 'datasets_processed/test.csv'\n",
    "    \n",
    "    # Save splits to CSV files\n",
    "    train_data.to_csv(train_path, index=False)\n",
    "    val_data.to_csv(val_path, index=False)\n",
    "    test_data.to_csv(test_path, index=False)\n",
    "    \n",
    "    print(f\"Train data shape: {train_data.shape}\")\n",
    "    print(f\"Validation data shape: {val_data.shape}\")\n",
    "    print(f\"Test data shape: {test_data.shape}\")\n",
    "    \n",
    "    return train_path, val_path, test_path\n",
    "\n",
    "train_path, val_path, test_path = process_and_split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'datasets_processed\\test.csv.dvc' 'datasets_processed\\.gitignore' 'datasets_processed\\validation.csv.dvc' 'datasets_processed\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Track split files with DVC\n",
    "!dvc add {train_path} {val_path} {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of target variable in first version:\n",
      "Dataset: datasets_processed/train.csv\n",
      "  Ham (0): 3374\n",
      "  Spam (1): 526\n",
      "  Total: 3900\n",
      "Dataset: datasets_processed/validation.csv\n",
      "  Ham (0): 725\n",
      "  Spam (1): 111\n",
      "  Total: 836\n",
      "Dataset: datasets_processed/test.csv\n",
      "  Ham (0): 726\n",
      "  Spam (1): 110\n",
      "  Total: 836\n"
     ]
    }
   ],
   "source": [
    "def print_target_distribution(file_path):\n",
    "    \"\"\"Print distribution of target variable in a dataset\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    counts = df['label'].value_counts()\n",
    "    \n",
    "    print(f\"Dataset: {file_path}\")\n",
    "    print(f\"  Ham (0): {counts.get(0, 0)}\")\n",
    "    print(f\"  Spam (1): {counts.get(1, 0)}\")\n",
    "    print(f\"  Total: {len(df)}\")\n",
    "\n",
    "print(\"\\nDistribution of target variable in first version:\")\n",
    "print_target_distribution(train_path)\n",
    "print_target_distribution(val_path)\n",
    "print_target_distribution(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'assignments/assignment_2/prepare.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tnew file:   .dvc/.gitignore\n",
      "\tnew file:   .dvc/config\n",
      "\tnew file:   .dvcignore\n",
      "\tnew file:   .gitignore\n",
      "\tnew file:   datasets_processed/.gitignore\n",
      "\tnew file:   datasets_processed/test.csv.dvc\n",
      "\tnew file:   datasets_processed/train.csv.dvc\n",
      "\tnew file:   datasets_processed/validation.csv.dvc\n",
      "\tnew file:   prepare.ipynb\n",
      "\tnew file:   raw_data.csv.dvc\n",
      "\tnew file:   sms_spam_collection/SMSSpamCollection\n",
      "\tnew file:   sms_spam_collection/readme\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tdeleted:    ../../.dvc/.gitignore\n",
      "\tdeleted:    ../../.dvc/config\n",
      "\tdeleted:    ../../.dvcignore\n",
      "\tdeleted:    ../.gitignore\n",
      "\tmodified:   ../assignment_1/prepare.ipynb\n",
      "\tmodified:   prepare.ipynb\n",
      "\tdeleted:    ../datasets_processed/.gitignore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 34160df] Added dataset with DVC\n",
      " 12 files changed, 6257 insertions(+)\n",
      " create mode 100644 assignments/assignment_2/.dvc/.gitignore\n",
      " create mode 100644 assignments/assignment_2/.dvc/config\n",
      " create mode 100644 assignments/assignment_2/.dvcignore\n",
      " create mode 100644 assignments/assignment_2/.gitignore\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/.gitignore\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/test.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/train.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/validation.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/prepare.ipynb\n",
      " create mode 100644 assignments/assignment_2/raw_data.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/sms_spam_collection/SMSSpamCollection\n",
      " create mode 100644 assignments/assignment_2/sms_spam_collection/readme\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Added dataset with DVC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data with random_state=1\n",
      "Train data shape: (3900, 2)\n",
      "Validation data shape: (836, 2)\n",
      "Test data shape: (836, 2)\n"
     ]
    }
   ],
   "source": [
    "train_path, val_path, test_path = process_and_split_data(df, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'datasets_processed\\test.csv.dvc' 'datasets_processed\\validation.csv.dvc' 'datasets_processed\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⠋ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Track split files with DVC\n",
    "!dvc add {train_path} {val_path} {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of target variable in first version:\n",
      "Dataset: datasets_processed/train.csv\n",
      "  Ham (0): 3383\n",
      "  Spam (1): 517\n",
      "  Total: 3900\n",
      "Dataset: datasets_processed/validation.csv\n",
      "  Ham (0): 718\n",
      "  Spam (1): 118\n",
      "  Total: 836\n",
      "Dataset: datasets_processed/test.csv\n",
      "  Ham (0): 724\n",
      "  Spam (1): 112\n",
      "  Total: 836\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDistribution of target variable in first version:\")\n",
    "print_target_distribution(train_path)\n",
    "print_target_distribution(val_path)\n",
    "print_target_distribution(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'assignments/assignment_2/prepare.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tmodified:   datasets_processed/test.csv.dvc\n",
      "\tmodified:   datasets_processed/train.csv.dvc\n",
      "\tmodified:   datasets_processed/validation.csv.dvc\n",
      "\tmodified:   prepare.ipynb\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   prepare.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 3262f13] Changed datasets(version 2)\n",
      " 4 files changed, 113 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Changed datasets(version 2)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the data versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8f7a747 Added data version 2 code\n",
      "3262f13 Changed datasets(version 2)\n",
      "03bf5d7 removed unwanted cells\n",
      "dddab9f file commit after adding first data version\n",
      "66bc15e changed gitignore locations\n",
      "34160df Added dataset with DVC\n",
      "ece5ace add gitignore\n",
      "6a3c32b Merge branch 'main' of github.com:chennasaisandeep/Applied-Machine-Learning\n",
      "195c8f1 Add first version of data splits with random_state=42\n",
      "3efe106 Delete assignments/assignment_1/main.ipynb\n",
      "6b3dee3 V01\n",
      "c223fda add assignment_1\n",
      "632509d add references and assignments folders\n",
      "58845ef Delete README.md\n",
      "0bdc347 first commit\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved working directory and index state WIP on (no branch): dddab9f file commit after adding first data version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'assignments/assignment_2/prepare.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "HEAD is now at dddab9f file commit after adding first data version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       datasets_processed\\validation.csv\n",
      "M       datasets_processed\\test.csv\n",
      "M       datasets_processed\\train.csv\n",
      "HEAD detached at dddab9f\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   prepare.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Dropped refs/stash@{0} (fe201d6d1f2228cdef567705de3a596d46d31c5a)\n"
     ]
    }
   ],
   "source": [
    "!git stash\n",
    "!git checkout dddab9f\n",
    "!dvc checkout\n",
    "!git stash pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of target variable in first version:\n",
      "Dataset: datasets_processed/train.csv\n",
      "  Ham (0): 3374\n",
      "  Spam (1): 526\n",
      "  Total: 3900\n",
      "Dataset: datasets_processed/validation.csv\n",
      "  Ham (0): 725\n",
      "  Spam (1): 111\n",
      "  Total: 836\n",
      "Dataset: datasets_processed/test.csv\n",
      "  Ham (0): 726\n",
      "  Spam (1): 110\n",
      "  Total: 836\n"
     ]
    }
   ],
   "source": [
    "# Define paths for split files\n",
    "train_path = 'datasets_processed/train.csv'\n",
    "val_path = 'datasets_processed/validation.csv'\n",
    "test_path = 'datasets_processed/test.csv'\n",
    "\n",
    "print(\"\\nDistribution of target variable in first version:\")\n",
    "print_target_distribution(train_path)\n",
    "print_target_distribution(val_path)\n",
    "print_target_distribution(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved working directory and index state WIP on (no branch): dddab9f file commit after adding first data version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'assignments/assignment_2/prepare.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "Previous HEAD position was dddab9f file commit after adding first data version\n",
      "HEAD is now at 8f7a747 Added data version 2 code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       datasets_processed\\test.csv\n",
      "M       datasets_processed\\train.csv\n",
      "M       datasets_processed\\validation.csv\n",
      "Auto-merging assignments/assignment_2/prepare.ipynb\n",
      "CONFLICT (content): Merge conflict in assignments/assignment_2/prepare.ipynb\n",
      "HEAD detached at 8f7a747\n",
      "Unmerged paths:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "  (use \"git add <file>...\" to mark resolution)\n",
      "\tboth modified:   prepare.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "The stash entry is kept in case you need it again.\n"
     ]
    }
   ],
   "source": [
    "!git stash\n",
    "!git checkout 8f7a747\n",
    "!dvc checkout\n",
    "!git stash pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of target variable in first version:\n",
      "Dataset: datasets_processed/train.csv\n",
      "  Ham (0): 3383\n",
      "  Spam (1): 517\n",
      "  Total: 3900\n",
      "Dataset: datasets_processed/validation.csv\n",
      "  Ham (0): 718\n",
      "  Spam (1): 118\n",
      "  Total: 836\n",
      "Dataset: datasets_processed/test.csv\n",
      "  Ham (0): 724\n",
      "  Spam (1): 112\n",
      "  Total: 836\n"
     ]
    }
   ],
   "source": [
    "# Define paths for split files\n",
    "train_path = 'datasets_processed/train.csv'\n",
    "val_path = 'datasets_processed/validation.csv'\n",
    "test_path = 'datasets_processed/test.csv'\n",
    "\n",
    "print(\"\\nDistribution of target variable in first version:\")\n",
    "print_target_distribution(train_path)\n",
    "print_target_distribution(val_path)\n",
    "print_target_distribution(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tassignments/assignment_2/prepare.ipynb\n",
      "Your branch is up to date with 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switched to branch 'main'\n"
     ]
    }
   ],
   "source": [
    "!git switch main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience_python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
