{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\saisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Download NLTK resources (only needed once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data from sms_spam_collection/SMSSpamCollection\n",
      "Loaded 5572 records\n",
      "Saving raw data to raw_data.csv\n",
      "Raw data saved raw_data.csv\n",
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add raw_data.csv.dvc .gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â ‹ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_raw_data(file_path):\n",
    "    \"\"\"Load raw SMS data from file\"\"\"\n",
    "    print(f\"Loading raw data from {file_path}\")\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'message'])\n",
    "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    return df\n",
    "\n",
    "def save_raw_data(df, path='raw_data.csv'):\n",
    "    \"\"\"Save raw data to CSV file and track with DVC\"\"\"\n",
    "    print(f\"Saving raw data to {path}\")\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"Raw data saved {path}\")\n",
    "\n",
    "# Load and save raw data\n",
    "filepath = 'sms_spam_collection/SMSSpamCollection'\n",
    "sms_data = load_raw_data(filepath)\n",
    "save_raw_data(sms_data)\n",
    "\n",
    "# Track the raw data file with DVC\n",
    "datapath = 'raw_data.csv'\n",
    "!dvc init --subdir\n",
    "!dvc add {datapath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "message",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3820ecfb-ba6e-4e43-90bb-83db70cb73be",
       "rows": [
        [
         "0",
         "0",
         "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat..."
        ],
        [
         "1",
         "0",
         "Ok lar... Joking wif u oni..."
        ],
        [
         "2",
         "1",
         "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
        ],
        [
         "3",
         "0",
         "U dun say so early hor... U c already then say..."
        ],
        [
         "4",
         "0",
         "Nah I don't think he goes to usf, he lives around here though"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('raw_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data with random_state=0\n",
      "Train data shape: (3900, 2)\n",
      "Validation data shape: (836, 2)\n",
      "Test data shape: (836, 2)\n"
     ]
    }
   ],
   "source": [
    "def process_and_split_data(df, random_state=0):\n",
    "    \"\"\"Process and split data into train/validation/test sets\"\"\"\n",
    "    print(f\"Splitting data with random_state={random_state}\")\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs('datasets_processed', exist_ok=True)\n",
    "    \n",
    "    # Split the data into train (70%), validation (15%), and test (15%) sets\n",
    "    train_data, temp_data = train_test_split(\n",
    "        df, \n",
    "        train_size=0.7, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, \n",
    "        test_size=0.5, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Define paths for split files\n",
    "    train_path = 'datasets_processed/train.csv'\n",
    "    val_path = 'datasets_processed/validation.csv'\n",
    "    test_path = 'datasets_processed/test.csv'\n",
    "    \n",
    "    # Save splits to CSV files\n",
    "    train_data.to_csv(train_path, index=False)\n",
    "    val_data.to_csv(val_path, index=False)\n",
    "    test_data.to_csv(test_path, index=False)\n",
    "    \n",
    "    print(f\"Train data shape: {train_data.shape}\")\n",
    "    print(f\"Validation data shape: {val_data.shape}\")\n",
    "    print(f\"Test data shape: {test_data.shape}\")\n",
    "    \n",
    "    return train_path, val_path, test_path\n",
    "\n",
    "train_path, val_path, test_path = process_and_split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'datasets_processed\\test.csv.dvc' 'datasets_processed\\.gitignore' 'datasets_processed\\validation.csv.dvc' 'datasets_processed\\train.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â ‹ Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Track split files with DVC\n",
    "!dvc add {train_path} {val_path} {test_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of target variable in first version:\n",
      "Dataset: datasets_processed/train.csv\n",
      "  Ham (0): 3374\n",
      "  Spam (1): 526\n",
      "  Total: 3900\n",
      "Dataset: datasets_processed/validation.csv\n",
      "  Ham (0): 725\n",
      "  Spam (1): 111\n",
      "  Total: 836\n",
      "Dataset: datasets_processed/test.csv\n",
      "  Ham (0): 726\n",
      "  Spam (1): 110\n",
      "  Total: 836\n"
     ]
    }
   ],
   "source": [
    "def print_target_distribution(file_path):\n",
    "    \"\"\"Print distribution of target variable in a dataset\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    counts = df['label'].value_counts()\n",
    "    \n",
    "    print(f\"Dataset: {file_path}\")\n",
    "    print(f\"  Ham (0): {counts.get(0, 0)}\")\n",
    "    print(f\"  Spam (1): {counts.get(1, 0)}\")\n",
    "    print(f\"  Total: {len(df)}\")\n",
    "\n",
    "print(\"\\nDistribution of target variable in first version:\")\n",
    "print_target_distribution(train_path)\n",
    "print_target_distribution(val_path)\n",
    "print_target_distribution(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: in the working copy of 'assignments/assignment_2/prepare.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\tnew file:   .dvc/.gitignore\n",
      "\tnew file:   .dvc/config\n",
      "\tnew file:   .dvcignore\n",
      "\tnew file:   .gitignore\n",
      "\tnew file:   datasets_processed/.gitignore\n",
      "\tnew file:   datasets_processed/test.csv.dvc\n",
      "\tnew file:   datasets_processed/train.csv.dvc\n",
      "\tnew file:   datasets_processed/validation.csv.dvc\n",
      "\tnew file:   prepare.ipynb\n",
      "\tnew file:   raw_data.csv.dvc\n",
      "\tnew file:   sms_spam_collection/SMSSpamCollection\n",
      "\tnew file:   sms_spam_collection/readme\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tdeleted:    ../../.dvc/.gitignore\n",
      "\tdeleted:    ../../.dvc/config\n",
      "\tdeleted:    ../../.dvcignore\n",
      "\tdeleted:    ../.gitignore\n",
      "\tmodified:   ../assignment_1/prepare.ipynb\n",
      "\tmodified:   prepare.ipynb\n",
      "\tdeleted:    ../datasets_processed/.gitignore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 34160df] Added dataset with DVC\n",
      " 12 files changed, 6257 insertions(+)\n",
      " create mode 100644 assignments/assignment_2/.dvc/.gitignore\n",
      " create mode 100644 assignments/assignment_2/.dvc/config\n",
      " create mode 100644 assignments/assignment_2/.dvcignore\n",
      " create mode 100644 assignments/assignment_2/.gitignore\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/.gitignore\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/test.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/train.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/datasets_processed/validation.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/prepare.ipynb\n",
      " create mode 100644 assignments/assignment_2/raw_data.csv.dvc\n",
      " create mode 100644 assignments/assignment_2/sms_spam_collection/SMSSpamCollection\n",
      " create mode 100644 assignments/assignment_2/sms_spam_collection/readme\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Added dataset with DVC\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience_python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
